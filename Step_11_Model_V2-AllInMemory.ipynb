{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGES = \"./data/imgs_v2/\"\n",
    "PATH_MODELS = \"./models/\"\n",
    "\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "if not(os.path.isdir(PATH_MODELS)):\n",
    "    os.mkdir(PATH_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_soft_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*14)])\n",
    "\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    try:\n",
    "#        # Currently, memory growth needs to be the same across GPUs\n",
    "#        for gpu in gpus:\n",
    "#            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#        # Memory growth must be set before GPUs have been initialized\n",
    "#        print(e)\n",
    "\n",
    "#import tensorflow_lattice as tfl\n",
    "print(tf.__version__)\n",
    "print(tf.keras.backend.image_data_format())\n",
    "import scipy.io \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def pinball_loss(y_true, y_pred, tau=.5):\n",
    "    \"\"\"Computes the pinball loss between `y_true` and `y_pred`.\n",
    "    `loss = maximum(tau * (y_true - y_pred), (tau - 1) * (y_true - y_pred))`\n",
    "    In the context of regression this, loss yields an estimator of the tau\n",
    "    conditional quantile.\n",
    "    See: https://en.wikipedia.org/wiki/Quantile_regression\n",
    "    Usage:\n",
    "    ```python\n",
    "    loss = pinball_loss([0., 0., 1., 1.], [1., 1., 1., 0.], tau=.1)\n",
    "    # loss = max(0.1 * (y_true - y_pred), (0.1 - 1) * (y_true - y_pred))\n",
    "    #      = (0.9 + 0.9 + 0 + 0.1) / 4\n",
    "    print('Loss: ', loss.numpy())  # Loss: 0.475\n",
    "    ```\n",
    "    Args:\n",
    "      y_true: Ground truth values. shape = `[batch_size, d0, .. dN]`\n",
    "      y_pred: The predicted values. shape = `[batch_size, d0, .. dN]`\n",
    "      tau: (Optional) Float in [0, 1] or a tensor taking values in [0, 1] and\n",
    "        shape = `[d0,..., dn]`.  It defines the slope of the pinball loss. In\n",
    "        the context of quantile regression, the value of tau determines the\n",
    "        conditional quantile level. When tau = 0.5, this amounts to l1\n",
    "        regression, an estimator of the conditional median (0.5 quantile).\n",
    "    Returns:\n",
    "        pinball_loss: 1-D float `Tensor` with shape [batch_size].\n",
    "    References:\n",
    "      - https://en.wikipedia.org/wiki/Quantile_regression\n",
    "      - https://projecteuclid.org/download/pdfview_1/euclid.bj/1297173840\n",
    "    \"\"\"\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "\n",
    "    # broadcast the pinball slope along the batch dimension, and clip to\n",
    "    # acceptable values\n",
    "    tau = tf.expand_dims(tf.cast(tau, y_pred.dtype), 0)\n",
    "    one = tf.cast(1, tau.dtype)\n",
    "\n",
    "    delta_y = y_true - y_pred\n",
    "    pinball = tf.math.maximum(tau * delta_y, (tau - one) * delta_y)\n",
    "    return tf.reduce_mean(tf.keras.backend.batch_flatten(pinball), axis=-1)\n",
    "\n",
    "\n",
    "class PinballLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Computes the pinball loss between `y_true` and `y_pred`.\n",
    "    `loss = maximum(tau * (y_true - y_pred), (tau - 1) * (y_true - y_pred))`\n",
    "    In the context of regression, this loss yields an estimator of the tau\n",
    "    conditional quantile.\n",
    "    See: https://en.wikipedia.org/wiki/Quantile_regression\n",
    "    Usage:\n",
    "    ```python\n",
    "    pinball = tfa.losses.PinballLoss(tau=.1)\n",
    "    loss = pinball([0., 0., 1., 1.], [1., 1., 1., 0.])\n",
    "    # loss = max(0.1 * (y_true - y_pred), (0.1 - 1) * (y_true - y_pred))\n",
    "    #      = (0.9 + 0.9 + 0 + 0.1) / 4\n",
    "    print('Loss: ', loss.numpy())  # Loss: 0.475\n",
    "    ```\n",
    "    Usage with the `compile` API:\n",
    "    ```python\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile('sgd', loss=tfa.losses.PinballLoss(tau=.1))\n",
    "    ```\n",
    "    Args:\n",
    "      tau: (Optional) Float in [0, 1] or a tensor taking values in [0, 1] and\n",
    "        shape = `[d0,..., dn]`.  It defines the slope of the pinball loss. In\n",
    "        the context of quantile regression, the value of tau determines the\n",
    "        conditional quantile level. When tau = 0.5, this amounts to l1\n",
    "        regression, an estimator of the conditional median (0.5 quantile).\n",
    "      reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to\n",
    "        loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n",
    "        option will be determined by the usage context. For almost all cases\n",
    "        this defaults to `SUM_OVER_BATCH_SIZE`.\n",
    "        When used with `tf.distribute.Strategy`, outside of built-in training\n",
    "        loops such as `tf.keras` `compile` and `fit`, using `AUTO` or\n",
    "        `SUM_OVER_BATCH_SIZE` will raise an error. Please see\n",
    "        https://www.tensorflow.org/alpha/tutorials/distribute/training_loops\n",
    "        for more details on this.\n",
    "      name: Optional name for the op.\n",
    "    References:\n",
    "      - https://en.wikipedia.org/wiki/Quantile_regression\n",
    "      - https://projecteuclid.org/download/pdfview_1/euclid.bj/1297173840\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tau=.5,\n",
    "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
    "                 name='pinball_loss'):\n",
    "        super(PinballLoss, self).__init__(reduction=reduction, name=name)\n",
    "        self.tau = tau\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return pinball_loss(y_true, y_pred, self.tau)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'tau': self.tau,\n",
    "        }\n",
    "        base_config = super(PinballLoss, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    \n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "\n",
    "def loader(path):\n",
    "    try:\n",
    "        im = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        #image = image * 1./255\n",
    "        #image = cv2.resize(image, (224,224)) # non need anymore they are all the same size now\n",
    "        return PIL.Image.fromarray(im)\n",
    "    except OSError:\n",
    "        print(\"Error:\", path)\n",
    "        return Image.new(\"RGB\", (224, 224), \"white\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/metadata_v3.pkl\")\n",
    "df.loc[df.MissingCount > 0, \"Split\"] = \"unused\"\n",
    "del df[\"Path\"]\n",
    "df = df.rename(columns={\"PathNew\":\"Path\"})\n",
    "df[[\"Recording\", \"PersonIdentity\", \"Frame\", \"Split\", \"Gaze\", \"Path\"]].to_pickle(\"./data/metadata_small_v2.pkl\")\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169672/169672 [02:19<00:00, 1217.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 26.3 s, total: 2min 20s\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_pickle(\"./data/metadata_small_v2.pkl\")\n",
    "df = df.sort_values([\"Recording\", \"PersonIdentity\", \"Frame\"])\n",
    "df.index = list(range(len(df)))\n",
    "\n",
    "# WARNING!\n",
    "# This only works with lots of memory ~45GB, use the generator which reads every step from disk\n",
    "# WARNING!\n",
    "df[\"Image\"] = df.Path.progress_apply(lambda x: loader(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train     110255\n",
       "unused     24219\n",
       "test       21072\n",
       "val        14126\n",
       "Name: Split, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random test image\n",
    "if True:\n",
    "    fig, ax = plt.subplots(3,5, figsize=(18,8))\n",
    "    for i in range (3):\n",
    "        for j in range (5):\n",
    "            path = df.sample().iloc[0].Path\n",
    "            img = loader(path)\n",
    "            enh_bri = PIL.ImageEnhance.Brightness(img)\n",
    "            img = enh_bri.enhance(random.uniform(.8,1.6))\n",
    "            enh_cont = PIL.ImageEnhance.Contrast(img)\n",
    "            img = enh_cont.enhance(random.uniform(.8,1.4))\n",
    "            #Image.Contrast(.8)\n",
    "            #PIL.ImageEnhance.Brightness(.8)\n",
    "            ax[i][j].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazeDataset(tf.data.Dataset):\n",
    "    def _generator(split, num_samples):\n",
    "        global df\n",
    "        \n",
    "        dataIndexList = list(df[df.Split == split.decode()].index)\n",
    "        while True:\n",
    "            random.shuffle(dataIndexList)\n",
    "            for idx in range(0, len(dataIndexList)-num_samples, num_samples):\n",
    "                lstImg = []\n",
    "                lstGaze = []\n",
    "                contrast = random.uniform(.8,1.4)\n",
    "                brightness = random.uniform(.8,1.6) # We know the images are overall dark\n",
    "                for sampleCounter in range(num_samples):\n",
    "                    nextIdx = dataIndexList[idx + sampleCounter]\n",
    "                    x = df.iloc[nextIdx - 3 : nextIdx + 4]\n",
    "                    lst = []\n",
    "                    for img in x.Image.to_list():\n",
    "                        enh_bri = PIL.ImageEnhance.Brightness(img)\n",
    "                        img = enh_bri.enhance(brightness)\n",
    "                        enh_cont = PIL.ImageEnhance.Contrast(img)\n",
    "                        img = enh_cont.enhance(contrast)\n",
    "                        img = np.array(img)\n",
    "                        img = img * 1./255\n",
    "                        lst.append(img)\n",
    "                    imgs = np.array(lst)\n",
    "                    gaze = x.iloc[3].Gaze\n",
    "                    lstImg.append(imgs)\n",
    "                    lstGaze.append(gaze)\n",
    "                yield np.stack(lstImg), np.stack(lstGaze)\n",
    "    \n",
    "    def __new__(cls, split, num_samples):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=(tf.float32, tf.float32),\n",
    "            output_shapes=([None, 7, 224,224,3], [None, 2]),\n",
    "            args=(split, num_samples,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-05 20:56:11.850287 0 0\n",
      "2020-04-05 20:56:12.683167 1 0\n",
      "2020-04-05 20:56:13.515941 2 0\n",
      "2020-04-05 20:56:14.314047 3 0\n",
      "2020-04-05 20:56:15.106786 4 0\n",
      "Execution time: 4.084275763481855\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def benchmark(dataset, num_epochs=5):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        i = 0\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            print(datetime.now(), epoch_num, i)\n",
    "            i = i + 1\n",
    "            break\n",
    "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
    "    \n",
    "benchmark(GazeDataset(\"train\", BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_Yaw(y_pred, y_true):\n",
    "    error = tf.math.abs(y_true[:,0] - y_pred[:,0])\n",
    "    error = 180.0 * tf.math.reduce_mean(error) / math.pi\n",
    "    return error\n",
    "\n",
    "def error_Pitch(y_pred, y_true):\n",
    "    error = tf.math.abs(y_true[:,1] - y_pred[:,1])\n",
    "    error = 180.0 * tf.math.reduce_mean(error) / math.pi\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_2 (TimeDist (None, 7, 1000)           3538984   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 7, 512)            512512    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 7, 128)            295424    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 4,445,994\n",
      "Trainable params: 907,010\n",
      "Non-trainable params: 3,538,984\n",
      "_________________________________________________________________\n",
      "Train for 11025 steps, validate for 1412 steps\n",
      "Epoch 1/80\n",
      "11025/11025 [==============================] - 3770s 342ms/step - loss: 0.2014 - error_Pitch: 11.2886 - error_Yaw: 34.8656 - val_loss: 0.4437 - val_error_Pitch: 32.0009 - val_error_Yaw: 69.6790\n",
      "Epoch 2/80\n",
      "11025/11025 [==============================] - 3754s 341ms/step - loss: 0.1794 - error_Pitch: 10.8820 - error_Yaw: 30.2260 - val_loss: 0.3078 - val_error_Pitch: 27.7779 - val_error_Yaw: 42.7606\n",
      "Epoch 3/80\n",
      "11025/11025 [==============================] - 3762s 341ms/step - loss: 0.1727 - error_Pitch: 10.7502 - error_Yaw: 28.8285 - val_loss: 0.2880 - val_error_Pitch: 22.4478 - val_error_Yaw: 43.5524\n",
      "Epoch 4/80\n",
      "11025/11025 [==============================] - 3784s 343ms/step - loss: 0.1715 - error_Pitch: 10.6486 - error_Yaw: 28.6489 - val_loss: 0.2913 - val_error_Pitch: 25.0635 - val_error_Yaw: 41.7073\n",
      "Epoch 5/80\n",
      "11025/11025 [==============================] - 3761s 341ms/step - loss: 0.1699 - error_Pitch: 10.6113 - error_Yaw: 28.3324 - val_loss: 0.2772 - val_error_Pitch: 21.4751 - val_error_Yaw: 42.0619\n",
      "Epoch 6/80\n",
      " 6804/11025 [=================>............] - ETA: 20:58 - loss: 0.1685 - error_Pitch: 10.6094 - error_Yaw: 28.0073"
     ]
    }
   ],
   "source": [
    "time = datetime.now()\n",
    "timeStr = str(time).split(\".\")[0].replace(\" \", \"-\").replace(\":\", \"-\")\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():\n",
    "resnet = tf.keras.applications.MobileNetV2()\n",
    "resnet.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((7, 224, 224, 3)),\n",
    "    tf.keras.layers.TimeDistributed(resnet),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(512)),\n",
    "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 128, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 64, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 64)),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=PinballLoss(), metrics=[error_Pitch, error_Yaw])\n",
    "\n",
    "\n",
    "\n",
    "path = \"%scrf.%s-gaze360{epoch:03d}-{val_loss:.4f}.hdf5.\" % (PATH_MODELS, time)\n",
    "callbackSaver = tf.keras.callbacks.ModelCheckpoint(path, monitor='val_loss')\n",
    "#model.fit_generator will be deprecated use fit instead\n",
    "history = model.fit(GazeDataset(\"train\", BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE),\n",
    "                    steps_per_epoch=int(len(df[df.Split == \"train\"])/BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=GazeDataset(\"val\", BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE),\n",
    "                    validation_steps=int(len(df[df.Split == \"val\"])/BATCH_SIZE),\n",
    "                    callbacks=[])\n",
    "                   #workers=30,\n",
    "                   #use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

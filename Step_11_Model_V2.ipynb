{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGES = \"./data/imgs_v2/\"\n",
    "PATH_MODELS = \"./models/\"\n",
    "\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "if not(os.path.isdir(PATH_MODELS)):\n",
    "    os.mkdir(PATH_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    try:\n",
    "#        # Currently, memory growth needs to be the same across GPUs\n",
    "#        for gpu in gpus:\n",
    "#            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#        # Memory growth must be set before GPUs have been initialized\n",
    "#        print(e)\n",
    "\n",
    "#import tensorflow_lattice as tfl\n",
    "print(tf.__version__)\n",
    "print(tf.keras.backend.image_data_format())\n",
    "import scipy.io \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def pinball_loss(y_true, y_pred, tau=.5):\n",
    "    \"\"\"Computes the pinball loss between `y_true` and `y_pred`.\n",
    "    `loss = maximum(tau * (y_true - y_pred), (tau - 1) * (y_true - y_pred))`\n",
    "    In the context of regression this, loss yields an estimator of the tau\n",
    "    conditional quantile.\n",
    "    See: https://en.wikipedia.org/wiki/Quantile_regression\n",
    "    Usage:\n",
    "    ```python\n",
    "    loss = pinball_loss([0., 0., 1., 1.], [1., 1., 1., 0.], tau=.1)\n",
    "    # loss = max(0.1 * (y_true - y_pred), (0.1 - 1) * (y_true - y_pred))\n",
    "    #      = (0.9 + 0.9 + 0 + 0.1) / 4\n",
    "    print('Loss: ', loss.numpy())  # Loss: 0.475\n",
    "    ```\n",
    "    Args:\n",
    "      y_true: Ground truth values. shape = `[batch_size, d0, .. dN]`\n",
    "      y_pred: The predicted values. shape = `[batch_size, d0, .. dN]`\n",
    "      tau: (Optional) Float in [0, 1] or a tensor taking values in [0, 1] and\n",
    "        shape = `[d0,..., dn]`.  It defines the slope of the pinball loss. In\n",
    "        the context of quantile regression, the value of tau determines the\n",
    "        conditional quantile level. When tau = 0.5, this amounts to l1\n",
    "        regression, an estimator of the conditional median (0.5 quantile).\n",
    "    Returns:\n",
    "        pinball_loss: 1-D float `Tensor` with shape [batch_size].\n",
    "    References:\n",
    "      - https://en.wikipedia.org/wiki/Quantile_regression\n",
    "      - https://projecteuclid.org/download/pdfview_1/euclid.bj/1297173840\n",
    "    \"\"\"\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "\n",
    "    # broadcast the pinball slope along the batch dimension, and clip to\n",
    "    # acceptable values\n",
    "    tau = tf.expand_dims(tf.cast(tau, y_pred.dtype), 0)\n",
    "    one = tf.cast(1, tau.dtype)\n",
    "\n",
    "    delta_y = y_true - y_pred\n",
    "    pinball = tf.math.maximum(tau * delta_y, (tau - one) * delta_y)\n",
    "    return tf.reduce_mean(tf.keras.backend.batch_flatten(pinball), axis=-1)\n",
    "\n",
    "\n",
    "class PinballLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Computes the pinball loss between `y_true` and `y_pred`.\n",
    "    `loss = maximum(tau * (y_true - y_pred), (tau - 1) * (y_true - y_pred))`\n",
    "    In the context of regression, this loss yields an estimator of the tau\n",
    "    conditional quantile.\n",
    "    See: https://en.wikipedia.org/wiki/Quantile_regression\n",
    "    Usage:\n",
    "    ```python\n",
    "    pinball = tfa.losses.PinballLoss(tau=.1)\n",
    "    loss = pinball([0., 0., 1., 1.], [1., 1., 1., 0.])\n",
    "    # loss = max(0.1 * (y_true - y_pred), (0.1 - 1) * (y_true - y_pred))\n",
    "    #      = (0.9 + 0.9 + 0 + 0.1) / 4\n",
    "    print('Loss: ', loss.numpy())  # Loss: 0.475\n",
    "    ```\n",
    "    Usage with the `compile` API:\n",
    "    ```python\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile('sgd', loss=tfa.losses.PinballLoss(tau=.1))\n",
    "    ```\n",
    "    Args:\n",
    "      tau: (Optional) Float in [0, 1] or a tensor taking values in [0, 1] and\n",
    "        shape = `[d0,..., dn]`.  It defines the slope of the pinball loss. In\n",
    "        the context of quantile regression, the value of tau determines the\n",
    "        conditional quantile level. When tau = 0.5, this amounts to l1\n",
    "        regression, an estimator of the conditional median (0.5 quantile).\n",
    "      reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to\n",
    "        loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n",
    "        option will be determined by the usage context. For almost all cases\n",
    "        this defaults to `SUM_OVER_BATCH_SIZE`.\n",
    "        When used with `tf.distribute.Strategy`, outside of built-in training\n",
    "        loops such as `tf.keras` `compile` and `fit`, using `AUTO` or\n",
    "        `SUM_OVER_BATCH_SIZE` will raise an error. Please see\n",
    "        https://www.tensorflow.org/alpha/tutorials/distribute/training_loops\n",
    "        for more details on this.\n",
    "      name: Optional name for the op.\n",
    "    References:\n",
    "      - https://en.wikipedia.org/wiki/Quantile_regression\n",
    "      - https://projecteuclid.org/download/pdfview_1/euclid.bj/1297173840\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tau=.5,\n",
    "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
    "                 name='pinball_loss'):\n",
    "        super(PinballLoss, self).__init__(reduction=reduction, name=name)\n",
    "        self.tau = tau\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return pinball_loss(y_true, y_pred, self.tau)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'tau': self.tau,\n",
    "        }\n",
    "        base_config = super(PinballLoss, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    \n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "\n",
    "def loader(path):\n",
    "    try:\n",
    "        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        image = image * 1./255\n",
    "        #image = cv2.resize(image, (224,224)) # non need anymore they are all the same size now\n",
    "        return image\n",
    "    except Exception:\n",
    "        print(\"Error:\", path)\n",
    "        return np.zeros((224,224,3))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/metadata_v3.pkl\")\n",
    "df = df[df.MissingCount == 0]\n",
    "del df[\"Path\"]\n",
    "df = df.rename(columns={\"PathNew\":\"Path\"})\n",
    "df[[\"Recording\", \"PersonIdentity\", \"Frame\", \"Split\", \"Gaze\", \"Path\"]].to_pickle(\"./data/metadata_small_v2.pkl\")\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/metadata_small_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording</th>\n",
       "      <th>PersonIdentity</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Split</th>\n",
       "      <th>Gaze</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>unused</td>\n",
       "      <td>[1.369981875570611, -0.2714605308163226]</td>\n",
       "      <td>./data/imgs_v2/rec_000/head/000000/000062.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>unused</td>\n",
       "      <td>[1.4035949460781183, -0.2777533378109644]</td>\n",
       "      <td>./data/imgs_v2/rec_000/head/000000/000063.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>unused</td>\n",
       "      <td>[1.466915275703859, -0.28671322379627373]</td>\n",
       "      <td>./data/imgs_v2/rec_000/head/000000/000064.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>unused</td>\n",
       "      <td>[1.4829930292285969, -0.29117835487262766]</td>\n",
       "      <td>./data/imgs_v2/rec_000/head/000000/000065.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>unused</td>\n",
       "      <td>[1.5390106484305224, -0.30402192051260135]</td>\n",
       "      <td>./data/imgs_v2/rec_000/head/000000/000066.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Recording PersonIdentity Frame   Split  \\\n",
       "3         0              0    62  unused   \n",
       "4         0              0    63  unused   \n",
       "5         0              0    64  unused   \n",
       "6         0              0    65  unused   \n",
       "7         0              0    66  unused   \n",
       "\n",
       "                                         Gaze  \\\n",
       "3    [1.369981875570611, -0.2714605308163226]   \n",
       "4   [1.4035949460781183, -0.2777533378109644]   \n",
       "5   [1.466915275703859, -0.28671322379627373]   \n",
       "6  [1.4829930292285969, -0.29117835487262766]   \n",
       "7  [1.5390106484305224, -0.30402192051260135]   \n",
       "\n",
       "                                            Path  \n",
       "3  ./data/imgs_v2/rec_000/head/000000/000062.jpg  \n",
       "4  ./data/imgs_v2/rec_000/head/000000/000063.jpg  \n",
       "5  ./data/imgs_v2/rec_000/head/000000/000064.jpg  \n",
       "6  ./data/imgs_v2/rec_000/head/000000/000065.jpg  \n",
       "7  ./data/imgs_v2/rec_000/head/000000/000066.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train     110255\n",
       "test       21072\n",
       "val        14126\n",
       "unused      6587\n",
       "Name: Split, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random test image\n",
    "if True:\n",
    "    fig, ax = plt.subplots(3,5, figsize=(18,8))\n",
    "    for i in range (3):\n",
    "        for j in range (5):\n",
    "            path = df.sample().iloc[0].Path\n",
    "            img = loader(path)\n",
    "            ax[i][j].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df):\n",
    "    fileNames = df.Path.to_list()\n",
    "    gazeDirs = df.Gaze.to_list()\n",
    "    images = []\n",
    "    for fileName, gazeDirs in zip(fileNames, gazeDirs):\n",
    "        frame_number = int(fileName.split('/')[-1][:-4])\n",
    "        lists_sources = []\n",
    "        for j in range(-3,4):\n",
    "            name_frame = '/'.join(fileName.split('/')[:-1]+['%0.6d.jpg'%(frame_number+j)])\n",
    "            lists_sources.append(name_frame)\n",
    "            \n",
    "        item = (lists_sources,gazeDirs)\n",
    "        images.append(item)\n",
    "    return images\n",
    "\n",
    "\n",
    "class GazeDataset(tf.data.Dataset):\n",
    "    def _generator(split, num_samples):\n",
    "        df = pd.read_pickle(\"./data/metadata_small_v2.pkl\")\n",
    "        df = df[df.Split == split.decode()]\n",
    "        data = make_dataset(df)\n",
    "        while True:\n",
    "            random.shuffle(data)\n",
    "            for idx in range(0, len(data)-num_samples, num_samples):\n",
    "                lstImg = []\n",
    "                lstGaze = []\n",
    "                for i in range(num_samples):\n",
    "                    path_source, gaze = data[idx+i]\n",
    "                    # Reading data (line, record) from the file\n",
    "                    imgs = []\n",
    "                    for i, frame_path in enumerate(path_source):\n",
    "                        img = loader(frame_path)\n",
    "                        imgs.append(img)\n",
    "                    lstGaze.append(gaze)\n",
    "                    lstImg.append(np.stack(imgs))  \n",
    "                    #print(tf.shape(imgs))\n",
    "\n",
    "                yield np.stack(lstImg), np.stack(lstGaze)\n",
    "                #yield np.array(lstImg), np.array(lstGaze)\n",
    "    \n",
    "    def __new__(cls, split, num_samples):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=(tf.float32, tf.float32),\n",
    "            output_shapes=([None, 7, 224,224,3], [None, 2]),\n",
    "            args=(split, num_samples,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        i = 0\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            print(datetime.now(), epoch_num, i)\n",
    "            i = i + 1\n",
    "            break\n",
    "    tf.print(\"Execution time:\", time.perf_counter() - start_time)\n",
    "    \n",
    "#benchmark(GazeDataset(\"train\", BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_Yaw(y_pred, y_true):\n",
    "    error = tf.math.abs(y_true[:,0] - y_pred[:,0])\n",
    "    error = 180.0 * tf.math.reduce_mean(error) / math.pi\n",
    "    return error\n",
    "\n",
    "def error_Pitch(y_pred, y_true):\n",
    "    error = tf.math.abs(y_true[:,1] - y_pred[:,1])\n",
    "    error = 180.0 * tf.math.reduce_mean(error) / math.pi\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 7, 1000)           3538984   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 7, 256)            256256    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 7, 256)            394240    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 4,584,234\n",
      "Trainable params: 1,045,250\n",
      "Non-trainable params: 3,538,984\n",
      "_________________________________________________________________\n",
      "Train for 5512 steps, validate for 706 steps\n",
      "Epoch 1/80\n",
      "5512/5512 [==============================] - 3110s 564ms/step - loss: 0.1857 - error_Pitch: 11.1635 - error_Yaw: 31.4022 - val_loss: 0.2611 - val_error_Pitch: 18.8775 - val_error_Yaw: 40.9716\n",
      "Epoch 2/80\n",
      "3119/5512 [===============>..............] - ETA: 19:49 - loss: 0.1724 - error_Pitch: 10.6759 - error_Yaw: 28.8296"
     ]
    }
   ],
   "source": [
    "time = datetime.now()\n",
    "timeStr = str(time).split(\".\")[0].replace(\" \", \"-\").replace(\":\", \"-\")\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#with strategy.scope():\n",
    "resnet = tf.keras.applications.MobileNetV2()\n",
    "resnet.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((7, 224, 224, 3)),\n",
    "    tf.keras.layers.TimeDistributed(resnet),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256)),\n",
    "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 128, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 128, return_sequences = True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 128)),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=PinballLoss(), metrics=[error_Pitch, error_Yaw])\n",
    "\n",
    "\n",
    "\n",
    "path = \"%scrf.%s-gaze360{epoch:03d}-{val_loss:.4f}.hdf5.\" % (PATH_MODELS, time)\n",
    "callbackSaver = tf.keras.callbacks.ModelCheckpoint(path, monitor='val_loss')\n",
    "#model.fit_generator will be deprecated use fit instead\n",
    "model.fit(GazeDataset(\"train\", BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE),\n",
    "                    steps_per_epoch=int(len(df[df.Split == \"train\"])/BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=GazeDataset(\"val\", BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE),\n",
    "                    validation_steps=int(len(df[df.Split == \"val\"])/BATCH_SIZE),\n",
    "                    callbacks=[])\n",
    "                   #workers=30,\n",
    "                   #use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

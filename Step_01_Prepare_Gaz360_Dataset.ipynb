{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGES = \"./data/imgs/\"\n",
    "\n",
    "#EPOCHS = 80\n",
    "#BATCH_SIZE = 5\n",
    "\n",
    "import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow_lattice as tfl\n",
    "#print(tf.__version__)\n",
    "#print(tf.keras.backend.image_data_format())\n",
    "import scipy.io \n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import cvlib\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"./data/metadata.pkl\"):\n",
    "    df = pd.read_pickle(\"./data/metadata.pkl\")\n",
    "else:\n",
    "    data = scipy.io.loadmat('./data/metadata.mat')\n",
    "    print(data.keys())\n",
    "    mappingSplits = {0: data[\"splits\"][0][0][0], 1: data[\"splits\"][0][1][0], 2: data[\"splits\"][0][2][0], 3:data[\"splits\"][0][3][0]}\n",
    "    print(mappingSplits)\n",
    "\n",
    "    df = pd.DataFrame([data[\"recording\"][0], data[\"split\"][0], data[\"gaze_dir\"], data[\"frame\"][0], data[\"person_identity\"][0]]).T\n",
    "    df.columns =  [\"Recording\", \"SplitId\", \"GazeDir\", \"Frame\", \"PersonIdentity\"]\n",
    "    df[\"Path\"] = df.apply(lambda e: \"%srec_%03d/head/%06d/%06d.jpg\" % (PATH_IMAGES, e.Recording, e.PersonIdentity, e.Frame), axis=1)\n",
    "    df[\"Split\"] = df.SplitId.map(mappingSplits)\n",
    "    df[\"GazeDirNorm\"] = df.GazeDir.apply(lambda x: x) # this seams to have no effect normalize()\n",
    "    df[\"Gaze\"] = df.GazeDirNorm.apply(lambda x: np.array([math.atan2(x[0],-x[2]), math.asin(x[1])]))\n",
    "    df[\"GazeAngle\"] = df.Gaze.apply(lambda x: np.rad2deg(x))\n",
    "    df[[\"Split\", \"Gaze\", \"Path\"]].to_pickle(\"./data/metadata_small.pkl\")\n",
    "    df.to_pickle(\"./data/metadata.pkl\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw = df.GazeAngle.apply(lambda x: x[0]).to_list()\n",
    "pitch = df.GazeAngle.apply(lambda x: x[1]).to_list()\n",
    "plt.hist(yaw, alpha = .5, label=\"Yaw\")\n",
    "plt.hist(pitch, alpha = .5, label=\"Pitch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.hist2d(yaw, pitch, bins=[np.arange(-180,180,2),np.arange(-90,90,2)], cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def countMissingFrames(df, f):\n",
    "    dfX = df[(df.Frame >= f-3) & (df.Frame <= f+3)]\n",
    "    return 7 - len(dfX)\n",
    "lst = []\n",
    "for i, r in enumerate(sorted(df.Recording.unique())):\n",
    "    if (i % 5 == 0):\n",
    "        print(\"%s: itr %i, Running recoding %i\" % (datetime.now(), i, r))\n",
    "    df1 = df[(df.Recording == r)]\n",
    "    for p in sorted(df1.PersonIdentity.unique()):\n",
    "        df2 = df1[(df1.PersonIdentity == p)]\n",
    "        ret = df2.Frame.apply(lambda x: countMissingFrames(df2, x))\n",
    "        lst.append(ret)\n",
    "        \n",
    "df[\"MissingCount\"] = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 7):\n",
    "    length = len(df[df.MissingCount == i])\n",
    "    print(\"%i missing images for %i images %.2f%%\" % (i, length, length/ len(df)* 100))\n",
    "df.MissingCount.hist(bins=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Split\", \"MissingCount\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not quite clear why 8702 good samples are not used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random test image\n",
    "if True:\n",
    "    fig, ax = plt.subplots(3,5, figsize=(18,8))\n",
    "    for i in range (3):\n",
    "        for j in range (5):\n",
    "            path = df[(df.PersonIdentity == 0) & (df.Recording == 1)].sample().iloc[0].Path\n",
    "            img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "            ax[i][j].imshow(img)\n",
    "            #faces, confidences = cvlib.detect_face(img)\n",
    "            #for f in faces:\n",
    "            #    ax[i][j].add_patch(patches.Rectangle((f[0], f[1]), f[2] - f[0], f[3] - f[1], linewidth=2, edgecolor='r', facecolor='none'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget http://arunponnusamy.com/files/mmod_human_face_detector.dat\n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"./mmod_human_face_detector.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def getFace(path):\n",
    "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    SIZE_ORG = img.shape\n",
    "    #faces, confidences = cvlib.detect_face(img, enable_gpu=False)\n",
    "    #cvlib.detect_face(img)\n",
    "    #cvlib.detect_face(img, enable_gpu=False) # not precice\n",
    "    \n",
    "    #import face_recognition\n",
    "    #face_recognition.face_locations(img, number_of_times_to_upsample=2, model=\"cnn\") # super slow\n",
    "    #face_recognition.batch_face_locations(frames, number_of_times_to_upsample=0) # Faster but combersome to use\n",
    "    \n",
    "    #https://www.arunponnusamy.com/cnn-face-detector-dlib.html\n",
    "    \n",
    "    SIZE = 500\n",
    "    img2 = cv2.resize(img, (SIZE,SIZE))\n",
    "    x = cnn_face_detector(img2)\n",
    "    \n",
    "    faces = [[a.rect.left()/SIZE*SIZE_ORG[0], a.rect.top()/SIZE*SIZE_ORG[0], a.rect.right()/SIZE*SIZE_ORG[1], a.rect.bottom()/SIZE*SIZE_ORG[1]] for a in x]\n",
    "    conf = [a.confidence for a in x]\n",
    "    return faces, conf, SIZE_ORG\n",
    "\n",
    "df[\"FaceData\"] = df.Path.progress_apply(lambda path: getFace(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Faces\"] = df.FaceData.apply(lambda x: x[0])\n",
    "df[\"FacesConfidence\"] = df.FaceData.apply(lambda x: x[1])\n",
    "df[\"Size\"] = df.FaceData.apply(lambda x: x[2])\n",
    "df[\"FaceCount\"] = df.Faces.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FaceCount\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Not recognized: %.2f\" %(len(df[df[\"FaceCount\"] == 0])/ len(df) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know for the given dataset the face has to be in the center of the frame\n",
    "# Thus, we can use the face which is closest to the center in case the face detaction found multiple faces\n",
    "# Demo for the next Setp:\n",
    "\n",
    "e = df[df.FaceCount==2].sample().iloc[0]\n",
    "path = e.Path\n",
    "img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "s = np.array(e.Size[:2])/2\n",
    "plt.scatter([s[0]],[s[1]], c=\"r\", marker=\"*\",label=\"Centre\")\n",
    "lst = []\n",
    "for i, f in enumerate(e.Faces):\n",
    "    f2 = np.array(f).reshape(2,2)\n",
    "    plt.scatter(f2[:,0], f2[:,1], label=\"Face %i\" % i)\n",
    "    \n",
    "    x, y = f[0], f[1]\n",
    "    w =  f[2] - f[0]\n",
    "    h = f[3] - f[1]\n",
    "    x1,y1 = x + w/2, y + h/2\n",
    "    distance = math.sqrt( ((x1-s[0])**2)+((y1-s[1])**2) )\n",
    "    print(i, distance)\n",
    "    plt.scatter([x1],[y1], marker=\"x\", label=\"Centre of %i\" % i)\n",
    "    lst.append(distance)\n",
    "plt.legend()\n",
    "idx = np.argmin(lst)\n",
    "print(idx, e.Faces[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneFace(faces, size, confidence):\n",
    "    if len(faces) == 0:\n",
    "        return None, None\n",
    "    elif len(faces) == 1:\n",
    "        return faces[0], confidence[0]\n",
    "    else:\n",
    "        lst = []\n",
    "        sizes = []\n",
    "        s = np.array(size[:2])/2\n",
    "        for f in faces:\n",
    "            x, y = f[0], f[1]\n",
    "            w =  f[2] - f[0]\n",
    "            h = f[3] - f[1]\n",
    "            sizes.append((w+h)/2)\n",
    "            x1,y1 = x + w/2, y + h/2\n",
    "            distance = math.sqrt( ((x1-s[0])**2)+((y1-s[1])**2) )\n",
    "            lst.append(distance)\n",
    "        \n",
    "        # No we use the bigger one of the ones close to the center\n",
    "        # This can and has to be done also with later validation datasets\n",
    "        # Thus, this makes the choise consistent and unique\n",
    "        lst = np.array(lst)\n",
    "        norm = lst / s[0]\n",
    "        idxs = np.argwhere(norm<.2)\n",
    "        idxs = np.ravel(idxs) # only indcies with a low distance to the centre - Dataset assumtiopn\n",
    "       \n",
    "        if len(idxs) < 2:\n",
    "            idx = np.argmin(lst)\n",
    "            return faces[idx], confidence[idx]\n",
    "        else:\n",
    "            sizes = np.array(sizes)[idxs]\n",
    "            idx = np.argmax(sizes) # Pick the biggest one. Do this for your database\n",
    "            return faces[idxs[idx]], confidence[idxs[idx]]\n",
    "        \n",
    "x = df.apply(lambda e: getOneFace(e.Faces, e.Size, e.FacesConfidence), axis = 1)   \n",
    "df[\"Face\"] = x.apply(lambda x: x[0])\n",
    "df[\"FaceConfidence\"] = x.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random test image\n",
    "if True:\n",
    "    fig, ax = plt.subplots(5,5, figsize=(18,18))\n",
    "    for i in range (5):\n",
    "        for j in range (5):\n",
    "            e = df[df.FaceCount==2].sample().iloc[0]\n",
    "            path = e.Path\n",
    "            img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "            ax[i][j].imshow(img)\n",
    "            \n",
    "            if e.FaceCount > 1:\n",
    "                for k, f in enumerate(e.Faces):\n",
    "                    #print(f[2] - f[0], f[3] - f[1])\n",
    "                    ax[i][j].add_patch(patches.Rectangle((f[0], f[1]), f[2] - f[0], f[3] - f[1], linewidth=2, edgecolor='y', facecolor='none'))\n",
    "                    ax[i][j].text(f[0], f[1], str(np.round(e.FacesConfidence[k], 2)), color=\"y\", size=14)\n",
    "            \n",
    "            f = e.Face\n",
    "            ax[i][j].add_patch(patches.Rectangle((f[0], f[1]), f[2] - f[0], f[3] - f[1], linewidth=2, edgecolor='r', facecolor='none'))\n",
    "            w =  f[2] - f[0]\n",
    "            h = f[3] - f[1]\n",
    "\n",
    "            ax[i][j].add_patch(patches.Rectangle((f[0]-w*.4, f[1]-h*.4),w*1.8, h*1.8, linewidth=2, edgecolor='w', facecolor='none'))\n",
    "            ax[i][j].text(f[0], f[1], str(np.round(e.FaceConfidence, 2)), color=\"r\", size=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Random test image\n",
    "if True:\n",
    "    fig, ax = plt.subplots(5,5, figsize=(18,18))\n",
    "    for i in range (5):\n",
    "        for j in range (5):\n",
    "            e = df[df.FaceCount==0].sample().iloc[0]\n",
    "            path = e.Path\n",
    "            img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "            ax[i][j].imshow(img)\n",
    "\n",
    "    plt.suptitle(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = df[df.FaceCount==0]\n",
    "yaw = dfX.GazeAngle.apply(lambda x: x[0]).to_list()\n",
    "pitch = dfX.GazeAngle.apply(lambda x: x[1]).to_list()\n",
    "plt.hist(yaw, alpha = .5, label=\"Yaw\")\n",
    "plt.hist(pitch, alpha = .5, label=\"Pitch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.hist2d(yaw, pitch, bins=[np.arange(-180,180,2),np.arange(-90,90,2)], cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = df[df.FaceCount==2].sample().iloc[0]\n",
    "f = e.Face\n",
    "path = e.Path\n",
    "\n",
    "img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.imshow(img)\n",
    "ax.add_patch(patches.Rectangle((f[0], f[1]), f[2] - f[0], f[3] - f[1], linewidth=2, edgecolor='r', facecolor='none'))\n",
    "w =  f[2] - f[0]\n",
    "h = f[3] - f[1]\n",
    "ax.add_patch(patches.Rectangle((f[0]-w*.4, f[1]-h*.4),w*1.8, h*1.8, linewidth=2, edgecolor='w', facecolor='none'))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getFaceCrop(path, f, s):\n",
    "    f = np.array(f).reshape((2,2))\n",
    "    s = np.array(s[:2])\n",
    "    SIZE = 500\n",
    "    f = np.ravel(f/s)\n",
    "    f = f* SIZE\n",
    "    # Enlarge face bounderyby 40%, needs to be applyed to evey new dataset / image\n",
    "    w =  (f[2] - f[0])*.4\n",
    "    h = (f[3] - f[1])*.4\n",
    "    f = np.round([f[0]-w, f[1]-h, f[2]+w, f[3]+h]).astype(int)\n",
    "\n",
    "    left, top, right, bottom = f\n",
    "    im = Image.open(path) \n",
    "    im = im.resize((SIZE,SIZE))\n",
    "    im = im.crop((left, top, right, bottom)) \n",
    "    return im.resize((224,224))\n",
    "    \n",
    "    #img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    #img2 = cv2.resize(img, (SIZE,SIZE))\n",
    "    #img2 = img2[f[0]:f[2], f[1]:f[3],:] # This method does not pad incase of minus values or larger faces than the image\n",
    "    #return img2\n",
    "    #return cv2.resize(img2, (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGES_NEW = \"./data/imgs_v2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateImageCrops(e):\n",
    "    if e.Face is None:\n",
    "        return None\n",
    "    else:\n",
    "        path = \"%srec_%03d/head/%06d/%06d.jpg\" % (PATH_IMAGES_NEW, e.Recording, e.PersonIdentity, e.Frame)\n",
    "        im = getFaceCrop(e.Path, e.Face, e.Size)\n",
    "        pathf_folder = \"%srec_%03d/head/%06d/\" % (PATH_IMAGES_NEW, e.Recording, e.PersonIdentity)\n",
    "        path = \"%s%06d.jpg\" % (pathf_folder, e.Frame)\n",
    "        os.makedirs(pathf_folder, exist_ok=True)\n",
    "        im.save(path)\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = df[df.FaceCount>0].sample()\n",
    "print(path)\n",
    "img = cv2.cvtColor(cv2.imread(dfX.iloc[0].Path), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "x = dfX.apply(lambda e: generateImageCrops(e), axis=1)\n",
    "path = x.iloc[0]\n",
    "print(path)\n",
    "img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df[\"PathNew\"] = df.progress_apply(lambda e: generateImageCrops(e), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./data/metadata_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./data/metadata_v2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.FaceCount > 0]\n",
    "df = df.sort_values([\"Recording\", \"PersonIdentity\", \"Frame\"])\n",
    "df.index = list(range(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the training we do not want to have to many or may be no gaps in the 7 frames.\n",
    "Checking for the amount of gaps in the follwoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RecordingDiff\"] = df.Recording.diff()\n",
    "df[\"PersonIdentityDiff\"] = df.PersonIdentity.diff()\n",
    "df[\"FrameDiff\"] = df.Frame.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX =df[(df.RecordingDiff == 0) & (df.PersonIdentityDiff == 0) & (df.FrameDiff != 1)]\n",
    "print(\"Gaps within one tracked face: %i (%.2f%%)\" % (len(dfX), len(dfX)/len(df)*100))\n",
    "dfX.FrameDiff.hist()\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#\n",
    "# This works but is super slow ETA ~2h\n",
    "# To much slicing is happening here\n",
    "#\n",
    "#def countMissingFrames(e):\n",
    "#    dfX = df[(df.Recording == e.Recording) & (df.PersonIdentity == e.PersonIdentity) & (df.Frame >= e.Frame-3) & (df.Frame <= e.Frame+3)]\n",
    "#    return 7 - len(dfX)\n",
    "#df[\"MissingCount\"] = df.progress_apply(lambda e: countMissingFrames(e), axis = 1)\n",
    "\n",
    "def countMissingFrames(df, f):\n",
    "    dfX = df[(df.Frame >= f-3) & (df.Frame <= f+3)]\n",
    "    return 7 - len(dfX)\n",
    "lst = []\n",
    "for i, r in enumerate(sorted(df.Recording.unique())):\n",
    "    if (i % 5 == 0):\n",
    "        print(\"%s: itr %i, Running recoding %i\" % (datetime.now(), i, r))\n",
    "    df1 = df[(df.Recording == r)]\n",
    "    for p in sorted(df1.PersonIdentity.unique()):\n",
    "        df2 = df1[(df1.PersonIdentity == p)]\n",
    "        ret = df2.Frame.apply(lambda x: countMissingFrames(df2, x))\n",
    "        lst.append(ret)\n",
    "        \n",
    "df[\"MissingCount\"] = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 7):\n",
    "    length = len(df[df.MissingCount == i])\n",
    "    print(\"%i missing images for %i images %.2f%%\" % (i, length, length/ len(df)* 100))\n",
    "df.MissingCount.hist(bins=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Split\", \"MissingCount\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./data/metadata_v3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is very little meaing to the training process when there are lots of images missing. Thus, we will remove them from the training list. However, not from the images itself as this will create even more missing images. \n",
    "\n",
    "We will showcase in the following what this means with respect to training the data dencity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFilter = df[df.MissingCount < 3]\n",
    "print (\" This removed %.2f%% of the samples\" % ((1-(len(dfFilter)/ len(df)))* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data split by sample in %\")\n",
    "(dfFilter.groupby(\"Split\").count().Frame / len(dfFilter)*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data split by number of people indentified - this is not the particiapnts count!\")\n",
    "dfFilter.groupby(\"Split\").PersonIdentity.unique().apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = dfFilter[dfFilter.Split == \"train\"]\n",
    "yaw = dfX.GazeAngle.apply(lambda x: x[0]).to_list()\n",
    "pitch = dfX.GazeAngle.apply(lambda x: x[1]).to_list()\n",
    "plt.hist(yaw, alpha = .5, label=\"Yaw\")\n",
    "plt.hist(pitch, alpha = .5, label=\"Pitch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.hist2d(yaw, pitch, bins=[np.arange(-180,180,2),np.arange(-90,90,2)], cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = dfFilter[dfFilter.Split == \"val\"]\n",
    "yaw = dfX.GazeAngle.apply(lambda x: x[0]).to_list()\n",
    "pitch = dfX.GazeAngle.apply(lambda x: x[1]).to_list()\n",
    "plt.hist(yaw, alpha = .5, label=\"Yaw\")\n",
    "plt.hist(pitch, alpha = .5, label=\"Pitch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.hist2d(yaw, pitch, bins=[np.arange(-180,180,2),np.arange(-90,90,2)], cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = dfFilter[dfFilter.Split == \"test\"]\n",
    "yaw = dfX.GazeAngle.apply(lambda x: x[0]).to_list()\n",
    "pitch = dfX.GazeAngle.apply(lambda x: x[1]).to_list()\n",
    "plt.hist(yaw, alpha = .5, label=\"Yaw\")\n",
    "plt.hist(pitch, alpha = .5, label=\"Pitch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.hist2d(yaw, pitch, bins=[np.arange(-180,180,2),np.arange(-90,90,2)], cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = df.sample().iloc[0]\n",
    "print(e.Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des = stats.describe(img.flatten())\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageInfo(path):\n",
    "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    img.flatten()\n",
    "    img = img.flatten()\n",
    "    return {\"Mean\":np.mean(img), \"SD\":np.std(img), \"Min\":np.min(img), \"Max\":np.max(img),  \"Skewness\":scipy.stats.skew(img)}\n",
    "                                                                                                                  \n",
    "                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = df.Path.progress_apply(lambda x: imageInfo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInfo = pd.DataFrame(info.tolist())\n",
    "dfInfo[\"Frame\"] = df.Frame\n",
    "dfInfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInfo.Mean.hist(label=\"Mean\", bins=25, alpha=.5)\n",
    "dfInfo.Max.hist(label=\"Max\", bins=25, alpha=.5)\n",
    "plt.xlim(0,255)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(e.PathNew), cv2.COLOR_BGR2RGB)\n",
    "equ = cv2.equalizeHist( cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(18,4))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cmap=\"gray\")\n",
    "ax[2].imshow(equ, cmap=\"gray\")\n",
    "\n",
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "ax[3].plot(cdf_normalized, color = 'b')\n",
    "ax[3].hist(img.flatten(),256,[0,256], color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
